# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jfsQA4trPGIloVge42LYbBIvaxAvpfCa
"""

import pandas as pd
data = pd.read_csv("train.csv")

data.columns

test=pd.read_csv("test.csv")

df_test = test.drop(['PassengerId', 'Name', 'Ticket', 'Embarked','Cabin','Sex'], axis=1)
df_test.fillna(df_test.mean(), inplace=True)

data.head()

data=data.dropna()

def preprocess(df):
    df = df.copy()

    def normalize_name(x):
        return " ".join([v.strip(",()[].\"'") for v in x.split(" ")])

    def ticket_number(x):
        return x.split(" ")[-1]

    def ticket_item(x):
        items = x.split(" ")
        if len(items) == 1:
            return "NONE"
        return "_".join(items[0:-1])

    data["Name"] = data["Name"].apply(normalize_name)
    data["Ticket_number"] = data["Ticket"].apply(ticket_number)
    data["Ticket_item"] = data["Ticket"].apply(ticket_item)
    return df

preprocessed_train_df = preprocess(data)


preprocessed_train_df.head(5)

x = data[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]
y = data['Survived']

from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=23)

x_train=x_train.dropna()
x_train

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report

hh=KNeighborsClassifier()
hh.fit(x_train,y_train)
y_pred=hh.predict(x_test)
print(classification_report(y_pred,y_test))
report = classification_report(y_test, y_pred)

from  sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(x_train, y_train)
y_pred=rf.predict(x_test)
print(classification_report(y_pred,y_test))

import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(5,)),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

import tensorflow as tf

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss="binary_crossentropy",
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=0,validation_data=(x_test, y_test))

print(history.history.keys())  # List of metric names recorded during training

# Plotting training loss over epochs
import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.show()

y_pred=model.predict(x_test)

import numpy as np

threshold = 0.5
y_pred = np.where(y_pred > threshold, 1, 0)

from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

import xgboost as xgb
xgb = xgb.XGBClassifier(objective = 'binary:logistic', max_depth = 3, random_state=42)
xgb.fit(x_train, y_train)
y_pred=xgb.predict(x_test)
print(classification_report(y_pred,y_test))

from sklearn.svm  import SVC
svc= SVC()
svc.fit(x_train,y_train)
y_pred=svc.predict(x_test)
print(classification_report(y_pred,y_test))

pip install catboost

from catboost import CatBoostClassifier
cat = CatBoostClassifier(verbose = 0)
cat.fit(x_train, y_train)
y_pred=cat.predict(x_test)
print(classification_report(y_pred,y_test))

pip install lightgbm

import lightgbm as lgb
params = {
    'boosting_type': 'gbdt',
    'objective': 'binary',  # For binary classification
    'metric': 'binary_error',  # Or other metrics such as 'binary_logloss'
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'verbose': 0
}
train_data = lgb.Dataset(x_train, label=y_train)
test_data = lgb.Dataset(x_test, label=y_test, reference=train_data)

num_round = 100
bst = lgb.train(params, train_data, num_round, valid_sets=[test_data])

y_pred = bst.predict(x_test, num_iteration=bst.best_iteration)

# Convert probabilities to binary predictions
y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred_binary)
print("Accuracy:", accuracy)

predictions=bst.predict(df_test)
len(predictions)
predictions = predictions.flatten()  # or predictions.ravel()
threshold = 0.50
predictions = np.where(predictions > threshold, 1, 0)

test_submission = pd.read_csv('test.csv')
submission = pd.DataFrame({'PassengerId': test_submission['PassengerId'], 'Survived': predictions})
submission.to_csv('submission.csv', header=True, index=False)
submission.head()